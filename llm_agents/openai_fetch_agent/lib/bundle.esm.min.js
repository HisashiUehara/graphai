import{sleep as e}from"graphai";var t,o={};var r,s=(t||(t=1,r=o,Object.defineProperty(r,"__esModule",{value:!0}),r.getMessages=r.getMergeValue=r.flatString=void 0,r.flatString=e=>Array.isArray(e)?e.filter((e=>e)).join("\n"):e??"",r.getMergeValue=(e,t,o,s)=>{const n=e[o],a=t[o];return n||a?[(0,r.flatString)(n),(0,r.flatString)(a)].filter((e=>e)).join("\n"):(0,r.flatString)(s)},void(r.getMessages=(e,t)=>[...e?[{role:"system",content:e}]:[],...t??[]])),o);const n="this is response result",a={object:"chat.completion",id:"chatcmpl-9N7HxXYbwjmdbdiQE94MHoVluQhyt",choices:[{message:{role:"assistant",content:n},finish_reason:"stop",index:0,logprobs:null}],created:1715296589,model:"gpt-3.5-turbo-0125"},p={name:"openAIFetchAgent",agent:async({filterParams:e,params:t,namedInputs:o})=>{const{verbose:r,system:n,images:a,temperature:p,tools:i,tool_choice:c,max_tokens:m,baseURL:y,apiKey:l,stream:g,prompt:u,messages:b,forWeb:d,response_format:h}={...t,...o},f=s.getMergeValue(o,t,"mergeablePrompts",u),_=s.getMergeValue(o,t,"mergeableSystem",n),j=s.getMessages(_,b);if(!l)throw new Error("OPENAI_API_KEY key is not set in params. params: {apiKey: 'sk-xxx'}");if(f&&j.push({role:"user",content:f}),a){const e="gpt-4-vision-preview"===t.model?a[0]:{url:a[0],detail:"high"};j.push({role:"user",content:[{type:"image_url",image_url:e}]})}r&&console.log(j);const k={model:t.model||"gpt-4o",messages:j,tools:i,tool_choice:c,max_tokens:m,temperature:p??.7,response_format:h},x=await fetch("https://api.openai.com/v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",Authorization:`Bearer ${l}`},body:JSON.stringify(k)});if(200===x.status){return((e,t)=>{const o=e?.choices[0]&&e?.choices[0].message?e?.choices[0].message:null,r=o&&o.content?o.content:null,s=o?.tool_calls&&o?.tool_calls[0]?o?.tool_calls[0]:null,n=s?{id:s.id,name:s?.function?.name,arguments:(()=>{try{return JSON.parse(s?.function?.arguments)}catch(e){return}})()}:void 0;return o&&t.push(o),{...e,text:r,tool:n,message:o,messages:t}})(await x.json(),j)}throw new Error("OPENAI API Error")},mock:async({filterParams:t})=>{for await(const o of n.split(""))t&&t.streamTokenCallback&&o&&(await e(100),t.streamTokenCallback(o));return a},inputs:{type:"object",properties:{model:{type:"string"},system:{type:"string"},tools:{type:"object"},tool_choice:{anyOf:[{type:"array"},{type:"object"}]},max_tokens:{type:"number"},verbose:{type:"boolean"},temperature:{type:"number"},baseURL:{type:"string"},apiKey:{anyOf:[{type:"string"},{type:"object"}]},stream:{type:"boolean"},prompt:{type:"string",description:"query string"},messages:{anyOf:[{type:"string"},{type:"object"},{type:"array"}],description:"chat messages"}}},output:{type:"object",properties:{id:{type:"string"},object:{type:"string"},created:{type:"integer"},model:{type:"string"},choices:{type:"array",items:[{type:"object",properties:{index:{type:"integer"},message:{type:"array",items:[{type:"object",properties:{content:{type:"string"},role:{type:"string"}},required:["content","role"]}]}},required:["index","message","logprobs","finish_reason"]}]},usage:{type:"object",properties:{prompt_tokens:{type:"integer"},completion_tokens:{type:"integer"},total_tokens:{type:"integer"}},required:["prompt_tokens","completion_tokens","total_tokens"]},text:{type:"string"},tool:{arguments:{type:"object"},name:{type:"string"}},message:{type:"object",properties:{content:{type:"string"},role:{type:"string"}},required:["content","role"]}},required:["id","object","created","model","choices","usage"]},params:{type:"object",properties:{model:{type:"string"},system:{type:"string"},tools:{type:"object"},tool_choice:{anyOf:[{type:"array"},{type:"object"}]},max_tokens:{type:"number"},verbose:{type:"boolean"},temperature:{type:"number"},baseURL:{type:"string"},apiKey:{anyOf:[{type:"string"},{type:"object"}]},stream:{type:"boolean"},prompt:{type:"string",description:"query string"},messages:{anyOf:[{type:"string"},{type:"object"},{type:"array"}],description:"chat messages"}}},outputFormat:{llmResponse:{key:"choices.$0.message.content",type:"string"}},samples:[{inputs:{prompt:n},params:{},result:a}],description:"OpenAI Fetch Agent",category:["llm"],author:"Receptron team",repository:"https://github.com/receptron/graphai",license:"MIT",stream:!0,npms:["openai"]};export{p as openAIFetchAgent};
//# sourceMappingURL=bundle.esm.min.js.map
